{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adri/miniconda3/envs/lattrans/lib/python3.6/site-packages/torch/utils/cpp_extension.py:286: UserWarning: \n",
      "\n",
      "                               !! WARNING !!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Your compiler (c++) is not compatible with the compiler Pytorch was\n",
      "built with for this platform, which is g++ on linux. Please\n",
      "use g++ to to compile your extension. Alternatively, you may\n",
      "compile PyTorch from source using c++, and then you can also use\n",
      "c++ to compile your extension.\n",
      "\n",
      "See https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md for help\n",
      "with compiling PyTorch from source.\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "                              !! WARNING !!\n",
      "\n",
      "  platform=sys.platform))\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "CUDA_HOME environment variable is not set. Please set it to your CUDA install root.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a76e643c739c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/latent-transformer/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pixel2style2pixel/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpixel2style2pixel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstylegan2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpixel2style2pixel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/latent-transformer/pixel2style2pixel/models/stylegan2/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstylegan2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFusedLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfused_leaky_relu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/latent-transformer/pixel2style2pixel/models/stylegan2/op/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfused_act\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFusedLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfused_leaky_relu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mupfirdn2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/latent-transformer/pixel2style2pixel/models/stylegan2/op/fused_act.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     sources=[\n\u001b[1;32m     12\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fused_bias_act.cpp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fused_bias_act_kernel.cu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     ],\n\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/lattrans/lib/python3.6/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mis_python_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mis_standalone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m         keep_intermediates=keep_intermediates)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lattrans/lib/python3.6/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1300\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m                         \u001b[0mwith_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_cuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                         is_standalone=is_standalone)\n\u001b[0m\u001b[1;32m   1303\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m                 \u001b[0mbaton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lattrans/lib/python3.6/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_write_ninja_file_and_build_library\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0mwith_cuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m         is_standalone)\n\u001b[0m\u001b[1;32m   1386\u001b[0m     \u001b[0mbuild_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'build.ninja'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lattrans/lib/python3.6/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_prepare_ldflags\u001b[0;34m(extra_ldflags, with_cuda, verbose, is_standalone)\u001b[0m\n\u001b[1;32m   1487\u001b[0m                 \u001b[0mextra_ldflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUDNN_HOME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lib/x64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mIS_HIP_EXTENSION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m             \u001b[0mextra_ldflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'-L{_join_cuda_home(\"lib64\")}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m             \u001b[0mextra_ldflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-lcudart'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mCUDNN_HOME\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lattrans/lib/python3.6/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_join_cuda_home\u001b[0;34m(*paths)\u001b[0m\n\u001b[1;32m   1980\u001b[0m     '''\n\u001b[1;32m   1981\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mCUDA_HOME\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m         raise EnvironmentError('CUDA_HOME environment variable is not set. '\n\u001b[0m\u001b[1;32m   1983\u001b[0m                                'Please set it to your CUDA install root.')\n\u001b[1;32m   1984\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUDA_HOME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: CUDA_HOME environment variable is not set. Please set it to your CUDA install root."
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2021, InterDigital R&D France. All rights reserved.\n",
    "#\n",
    "# This source code is made available under the license found in the\n",
    "# LICENSE.txt in the root directory of this source tree.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import yaml\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "import sys\n",
    "\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    sys.path.append('..')\n",
    "    os.chdir('..')\n",
    "    \n",
    "from datasets import *\n",
    "from trainer import *\n",
    "from utils.functions import *\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "device = torch.device('cuda')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', type=str, default='003', help='Path to the config file.')\n",
    "parser.add_argument('--attr', type=str, default='Eyeglasses', help='attribute for manipulation.')\n",
    "parser.add_argument('--latent_path', type=str, default='./data/celebahq_dlatents_psp.npy', help='dataset path')\n",
    "parser.add_argument('--label_file', type=str, default='./data/celebahq_anno.npy', help='label file path')\n",
    "parser.add_argument('--stylegan_model_path', type=str, default='./pixel2style2pixel/pretrained_models/psp_ffhq_encode.pt', help='stylegan model path')\n",
    "parser.add_argument('--classifier_model_path', type=str, default='./models/latent_classifier_epoch_20.pth', help='pretrained attribute classifier')\n",
    "parser.add_argument('--log_path', type=str, default='./logs/', help='log file path')\n",
    "opts = parser.parse_args([])\n",
    "\n",
    "# Celeba attribute list\n",
    "attr_dict = {'5_o_Clock_Shadow': 0, 'Arched_Eyebrows': 1, 'Attractive': 2, 'Bags_Under_Eyes': 3, \\\n",
    "            'Bald': 4, 'Bangs': 5, 'Big_Lips': 6, 'Big_Nose': 7, 'Black_Hair': 8, 'Blond_Hair': 9, \\\n",
    "            'Blurry': 10, 'Brown_Hair': 11, 'Bushy_Eyebrows': 12, 'Chubby': 13, 'Double_Chin': 14, \\\n",
    "            'Eyeglasses': 15, 'Goatee': 16, 'Gray_Hair': 17, 'Heavy_Makeup': 18, 'High_Cheekbones': 19, \\\n",
    "            'Male': 20, 'Mouth_Slightly_Open': 21, 'Mustache': 22, 'Narrow_Eyes': 23, 'No_Beard': 24, \\\n",
    "            'Oval_Face': 25, 'Pale_Skin': 26, 'Pointy_Nose': 27, 'Receding_Hairline': 28, 'Rosy_Cheeks': 29, \\\n",
    "            'Sideburns': 30, 'Smiling': 31, 'Straight_Hair': 32, 'Wavy_Hair': 33, 'Wearing_Earrings': 34, \\\n",
    "            'Wearing_Hat': 35, 'Wearing_Lipstick': 36, 'Wearing_Necklace': 37, 'Wearing_Necktie': 38, 'Young': 39}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer model.\n",
    "log_dir = os.path.join(opts.log_path, opts.config) + '/'\n",
    "config = yaml.load(open('./configs/' + opts.config + '.yaml', 'r'))\n",
    "\n",
    "trainer = Trainer(config, None, None, opts.label_file)\n",
    "trainer.initialize(opts.stylegan_model_path, opts.classifier_model_path)   \n",
    "trainer.to(device)\n",
    "\n",
    "testdata_dir = './data/supple/'\n",
    "latent_list = glob.glob1(testdata_dir,'*.npy')\n",
    "latent_list.sort()\n",
    "\n",
    "attrs_list = [{'Arched_Eyebrows':1, 'Chubby':-0.5, 'Pointy_Nose':-1, 'Smiling':-1, 'Pale_Skin':1}, \\\n",
    "                {'Black_Hair':1, 'Smiling':1, 'Bags_Under_Eyes':1, 'Young':1, 'Eyeglasses':1.2}, \\\n",
    "                {'Chubby':-0.5, 'Bangs':1, 'Smiling':1, 'Young':-1, 'Heavy_Makeup':1}, \\\n",
    "                {'Chubby':-0.5, 'Smiling':-1, 'Narrow_Eyes':-0.5, 'Heavy_Makeup':1, 'Eyeglasses':1}, \\\n",
    "                {'Eyeglasses':-1.2, 'Smiling':1, 'Goatee':1, 'Arched_Eyebrows':1, 'Young':1}, \\\n",
    "                {'No_Beard':-1, 'Bushy_Eyebrows':1, 'Mouth_Slightly_Open':1, 'Receding_Hairline':1, 'Eyeglasses':1.2}, \\\n",
    "                {'Smiling':-1, 'Chubby':-0.5, 'No_Beard':-1, 'Eyeglasses':1.2, 'Receding_Hairline':1}, \\\n",
    "                {'Smiling':1, 'Goatee':1, 'Eyeglasses':-1, 'Arched_Eyebrows':-1, 'Young':1}  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single attribute manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for k, latent in enumerate(latent_list):\n",
    "\n",
    "        w_0 = np.load(testdata_dir + latent)\n",
    "        w_0 = torch.tensor(w_0).to(device)\n",
    "        \n",
    "        idx =  [int(s) for s in latent.replace('_','.').split('.') if s.isdigit()][0]\n",
    "        x_0 = img_to_tensor(Image.open(testdata_dir + '%05d.jpg'%idx))\n",
    "        x_0 = x_0.unsqueeze(0).to(device)\n",
    "        img_l = [x_0] # original image\n",
    "        \n",
    "        x_1, _ = trainer.StyleGAN([w_0], input_is_latent=True, randomize_noise=False)\n",
    "        x_0 = torch.ones((x_1.size(0), x_1.size(1), x_1.size(2),x_1.size(3)+40)).type_as(x_1)\n",
    "        x_0[:,:,:,20:1044] = x_1[:,:,:,:]\n",
    "        img_l.append(x_0) # projected image\n",
    "        \n",
    "        attrs = attrs_list[k]\n",
    "        for attr in list(attrs.keys()):\n",
    "            \n",
    "            trainer.attr_num = attr_dict[attr]\n",
    "            trainer.load_model(log_dir)\n",
    "            \n",
    "            alpha = torch.tensor(1.0) * attrs[attr]\n",
    "            w_1 = trainer.T_net(w_0.view(w_0.size(0), -1), alpha.unsqueeze(0).to(device))\n",
    "            w_1 = w_1.view(w_0.size())\n",
    "            w_1 = torch.cat((w_1[:,:11,:], w_0[:,11:,:]), 1)\n",
    "            x_1, _ = trainer.StyleGAN([w_1], input_is_latent=True, randomize_noise=False)\n",
    "            img_l.append(x_1.data)\n",
    "\n",
    "        img = img_l[0] if len(img_l)==1 else torch.cat(img_l, 3)\n",
    "        img = np.clip(clip_img(img)[0].cpu().numpy()*255.,0,255).astype(np.uint8)\n",
    "        img = Image.fromarray(img.transpose(1,2,0))\n",
    "        plt.figure(figsize=(30,5))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential attribute manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    for k, latent in enumerate(latent_list):\n",
    "\n",
    "        w_0 = np.load(testdata_dir + latent)\n",
    "        w_0 = torch.tensor(w_0).to(device)\n",
    "        \n",
    "        idx =  [int(s) for s in latent.replace('_','.').split('.') if s.isdigit()][0]\n",
    "        x_0 = img_to_tensor(Image.open(testdata_dir + '%05d.jpg'%idx))\n",
    "        x_0 = x_0.unsqueeze(0).to(device)\n",
    "        img_l = [x_0] # original image\n",
    "        \n",
    "        x_1, _ = trainer.StyleGAN([w_0], input_is_latent=True, randomize_noise=False)\n",
    "        x_0 = torch.ones((x_1.size(0), x_1.size(1), x_1.size(2),x_1.size(3)+40)).type_as(x_1)\n",
    "        x_0[:,:,:,20:1044] = x_1[:,:,:,:]\n",
    "        img_l.append(x_0) # projected image\n",
    "        \n",
    "        attrs = attrs_list[k]\n",
    "        w_1 = w_0\n",
    "        for attr in list(attrs.keys()):\n",
    "            \n",
    "            trainer.attr_num = attr_dict[attr]\n",
    "            trainer.load_model(log_dir)\n",
    "            \n",
    "            alpha = torch.tensor(1.0) * attrs[attr]\n",
    "            w_1 = trainer.T_net(w_1.view(w_0.size(0), -1), alpha.unsqueeze(0).to(device))\n",
    "            w_1 = w_1.view(w_0.size())\n",
    "            w_1 = torch.cat((w_1[:,:11,:], w_0[:,11:,:]), 1)\n",
    "            x_1, _ = trainer.StyleGAN([w_1], input_is_latent=True, randomize_noise=False)\n",
    "            img_l.append(x_1.data)\n",
    "\n",
    "        img = img_l[0] if len(img_l)==1 else torch.cat(img_l, 3)\n",
    "        img = np.clip(clip_img(img)[0].cpu().numpy()*255.,0,255).astype(np.uint8)\n",
    "        img = Image.fromarray(img.transpose(1,2,0))\n",
    "        plt.figure(figsize=(30,5))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lattrans",
   "language": "python",
   "name": "lattrans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
